import networkx as nx
import random
from collections import Counter
import numpy as np

def generate_erdos_renyi_graph(n, p):
    """
    Genera un grafo Erdős-Rényi (G(n, p)) conectado.
    Parámetros:
    - n (int): Número de nodos.
    - p (float): Probabilidad de creación de una arista entre cualquier par de nodos.
    Retorna:
    - G (networkx.Graph): Un grafo Erdős-Rényi conectado.
    """
    G = nx.erdos_renyi_graph(n, p, seed=30)
    if not nx.is_connected(G):
        # Extrae el componente conectado más grande si el grafo no está conectado
        print(f"Erdős-Rényi graph with p={p} is not connected. Extracting the largest connected component.")
        G = G.subgraph(max(nx.connected_components(G), key=len)).copy()
    return G


#generate Albert-Barabasi graph
def generate_albert_barabasi_graph(n, m):
    """
    Genera un grafo de Preferencia (Scale-Free) conectado usando el modelo de Barabási-Albert.

    Parámetros:
    - n (int): Número de nodos.
    - m (int): Número de aristas a adjuntar de un nuevo nodo a nodos existentes.

    Retorna:
    - G (networkx.Graph): Un grafo de Preferencia conectado.
    """
    G = nx.barabasi_albert_graph(n, m, seed=30)
    if not nx.is_connected(G):
        # Extrae el componente conectado más grande si el grafo no está conectado
        print(f"Scale-Free graph with m={m} is not connected. Extracting the largest connected component.")
        G = G.subgraph(max(nx.connected_components(G), key=len)).copy()
    return G


# Stochastic Block Model Generator
def generate_sbm(sizes_sbm, p_intra, p_inter):
    # sizes_sbm: array - length of this array determines number of blocks,
    #                    each entry indicates number of nodes per block
    # p_intra: constant - probability of connection between nodes inside same block (in [0,1])
    # p_inter: constant - probability of connection between nodes in different blocks (in [0,1])

    # Define the probability matrix
    probs_sbm = [[p_intra if i == j else p_inter for j in range(len(sizes_sbm))] for i in range(len(sizes_sbm))]
    # Generate SBM graph
    G_sbm = nx.stochastic_block_model(sizes_sbm, probs_sbm, seed=42)
    # Check if the graph is connected
    while nx.is_connected(G_sbm) == False:
        print("Original graph was not connected. Generating a new one")
        G_sbm = nx.stochastic_block_model(sizes_sbm, probs_sbm, seed=42)
    print(f"SBM Graph: {G_sbm.number_of_nodes()} nodes, {G_sbm.number_of_edges()} edges")

    return G_sbm


# Configuration Model
def generate_configuration_model(degree_sequence):
    """
    Generate a random graph using the Configuration Model.

    :param degree_sequence: List of integers representing the degree of each node.
    :return: A NetworkX graph generated by the Configuration Model.
    """
    # Check if the degree sequence is valid
    if sum(degree_sequence) % 2 != 0:
        raise ValueError("The sum of the degree sequence must be even.")

    # Generate the graph using NetworkX's configuration model
    G = nx.configuration_model(degree_sequence)

    # Convert the graph to a simple graph (no parallel edges or self-loops)
    G = nx.Graph(G)  # Remove parallel edges
    G.remove_edges_from(nx.selfloop_edges(G))  # Remove self-loops

    return G


# Hierarchical Configuration Model
def generate_hierarchical_configuration_model(in_degree_sequence, ext_degree_sequence, community_sizes):
    """
    Generate a random graph using the Hierarchical Configuration Model
    :param in_degree_sequence: List of integers representing the inner degree of each vertex (connections with vertices
                                inside the same community)
    :param ext_degree_sequence: List of integers representing the outer degree of each vertex (connections with vertices
                                outside the community)
    :param community_sizes: List of integers representing the size of each community (length of this list determines
                            number of communities)
    :return: A NetworkX graph generated by the Hierarchical Configuration Model
    """
    n = len(in_degree_sequence)

    # check the introduced data passes first inspection
    if n != len(ext_degree_sequence) or n != sum(community_sizes):
        raise ValueError("The length of the inside degrees sequence, the outside degrees sequence and the total "
                         "number of vertices specified by the community_sizes list must be equal")

    # create graph
    G = nx.empty_graph(0, nx.MultiGraph)

    # create intra community edges, prepare inter community edges
    offset = 0
    outer_half_edges = []
    for h, size_h in enumerate(community_sizes):
        # get inter community half-edges, store them in list of lists
        ext_degrees_h = ext_degree_sequence[offset:offset + size_h]
        outer_half_edges.append([i + offset for i, count in enumerate(ext_degrees_h) for _ in range(count)])

        # get intra community edges
        in_degrees_h = in_degree_sequence[offset:offset + size_h]

        # check data is consistent
        if sum(in_degrees_h) % 2 != 0:
            raise ValueError("The sum of the inner degree sequence for each community must be even")

        # get intra community half_edges
        half_edges_h = [i + offset for i, count in enumerate(in_degrees_h) for _ in range(count)]
        half_h = len(half_edges_h) // 2
        random.shuffle(half_edges_h)
        first_half_h, second_half_h = half_edges_h[:half_h], half_edges_h[half_h:]
        first_half_h = np.array(first_half_h)
        second_half_h = np.array(second_half_h)
        stacked = np.vstack((first_half_h, second_half_h)).T
        new_internal_edges = [tuple(row) for row in stacked]
        G.add_edges_from(new_internal_edges)
        offset += size_h

    # create inter community edges
    ext_edges = []
    while any(outer_half_edges):
        # Select community with the highest number of outer half-edges remaining
        non_empty_sublists = [lst for lst in outer_half_edges if lst]
        community = max(non_empty_sublists, key=len, default=[])

        #select one half edge from the community with the highest number of outer half-edges remaining
        half_edge = random.choice(community)
        community.remove(half_edge)
        new_ext_edge = ()
        new_ext_edge += (half_edge,)

        #Select a random community and a random half-edge from that community
        # (excluding the one we sampled the first half-edge from)
        selected_community = random.choice([lst for lst in non_empty_sublists if lst != community])
        selected_half_edge = random.choice(selected_community)
        selected_community.remove(selected_half_edge)
        new_ext_edge += (selected_half_edge,)

        # Randomly select two communities
        #non_empty_sublists = [lst for lst in outer_half_edges if lst]
        #selected_communities = random.sample(non_empty_sublists, 2)

        # Randomly select an outer half edge of each community, create and edge with them
        #new_ext_edge = ()
        #for community in selected_communities:
        #   selected_half_edge = random.choice(community)
        #    community.remove(selected_half_edge)
        #    new_ext_edge += (selected_half_edge,)

        ext_edges.append(new_ext_edge)

    G.add_edges_from(ext_edges)

    return G



def preferential_attachment_with_colors(num_nodes, num_edges, labels, size_init_graph, label, delta):
    """At each step adds a node with a number of edges (predefined), which gets attached to other nodes
       with probability based on the degree of each nodes (the greater the degree, the greater the probability).
       This node gets a label according to the most common label between its neighbors.

    Args:
        num_nodes (int): number of nodes to be added to the initial graph
        num_edges (int): number of edges each new node has
        labels (dict): dict with possible labels as keys, and probability of each label as values (to generate initial graph)
        size_init_graph (int): size of initial graph
        label (str): attribute to update.
        delta (float): positive parameter to assure probability of matching a degree 0 verter is positive

    Returns:
        graph
    """
    # Initialize a small random graph with labeled nodes
    initial_labels=[]
    for _ in range(size_init_graph):
        initial_labels += [random.choices(population=list(labels.keys()),
                                         weights=list(labels.values()),
                                         k=1)[0]]
    initial_graph = nx.gnm_random_graph(len(initial_labels), len(initial_labels) // 2)
    for i, feature in enumerate(initial_labels):
        initial_graph.nodes[i][label] = feature

    # Create a copy to work on
    graph = initial_graph.copy()

    for new_node in range(len(labels), len(labels) + num_nodes):
        # Compute the degrees and probabilities for existing nodes
        degrees = nx.degree(graph)
        total_degree = sum(dict(degrees).values())

        # Attach the new node to num_edges existing nodes based on preferential attachment
        targets = set()
        while len(targets) < num_edges:
            chosen = random.choices(
                population=list(graph.nodes),
                weights=[(degrees[node]+delta)/(total_degree+delta) for node in graph.nodes],
                k=1
            )[0]
            targets.add(chosen)

        # Add the new node and connect it to the chosen targets
        graph.add_node(new_node)
        for target in targets:
            graph.add_edge(new_node, target)

        # Determine the label for the new node based on majority vote of neighbors
        neighbor_labels = [graph.nodes[neighbor][label] for neighbor in targets]
        label_counter = Counter(neighbor_labels)
        majority_label = label_counter.most_common(1)[0][0]  # Get the most common label
        graph.nodes[new_node][label] = majority_label
    if not nx.is_connected(graph):
        # Extrae el componente conectado más grande si el grafo no está conectado
        print(f"Scale-Free graph with m={num_edges} is not connected. Extracting the largest connected component.")
        graph = graph.subgraph(max(nx.connected_components(graph), key=len)).copy()

    return graph